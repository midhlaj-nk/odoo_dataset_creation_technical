{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Generate Odoo Dataset with AI Descriptions (Kaggle Edition)\n",
                "\n",
                "This notebook runs a background job to generating an Odoo 19.0 dataset with AI-enhanced descriptions using a local LLM (Llama 3 via Ollama).\n",
                "\n",
                "### **Prerequisites (Before Running)**\n",
                "1. **Internet Access**: Enable \"Internet\" in the Notebook Settings (Right Panel).\n",
                "2. **GPU Accelerator**: Select **GPU T4 x2** (or GPU P100) in the Notebook Settings. \n",
                "   * *Do NOT use TPU.*\n",
                "\n",
                "### **How to Run for Vacation (Background Mode)**\n",
                "1. Click **\"Save Version\"** (Top Right).\n",
                "2. Select **\"Save & Run All (Commit)\"**.\n",
                "3. Click **Save**.\n",
                "\n",
                "This will start a background session that runs for up to **12 hours**. You can close the browser and check back later."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Install Dependencies & Setup Ollama\n",
                "# We install Ollama (AI Engine) and Python libraries\n",
                "\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "!pip install pandas openpyxl requests tqdm openai"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2: Start Ollama Server (Background Process)\n",
                "import subprocess\n",
                "import time\n",
                "\n",
                "print(\"Starting Ollama Server...\")\n",
                "process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
                "time.sleep(10)  # Give it time to boot up\n",
                "\n",
                "print(\"Pulling Llama 3 model (this may take a few minutes)...\")\n",
                "!ollama pull llama3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 3: Clone Resources\n",
                "# 1. Clone Odoo 19.0 Source Code\n",
                "print(\"Cloning Odoo 19.0 source code...\")\n",
                "!git clone --depth 1 --branch 19.0 https://github.com/odoo/odoo.git odoo-19.0\n",
                "\n",
                "# 2. Clone the Generation Script from your Repo\n",
                "print(\"Cloning generation script...\")\n",
                "!rm -rf odoo_dataset_creation_technical # Cleanup if exists\n",
                "!git clone https://github.com/midhlaj-nk/odoo_dataset_creation_technical.git odoo_dataset_creation_technical"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 4: Run the Generation Script\n",
                "# This is the main process that will run for hours.\n",
                "\n",
                "import os\n",
                "\n",
                "# Define Paths\n",
                "working_dir = \"/kaggle/working\"\n",
                "script_path = f\"{working_dir}/odoo_dataset_creation_technical/generate_odoo_dataset.py\"\n",
                "odoo_source = f\"{working_dir}/odoo-19.0\"\n",
                "output_file = f\"{working_dir}/odoo_19_full_dataset_ai.xlsx\"\n",
                "\n",
                "print(\"Starting Dataset Generation...\")\n",
                "print(f\"Script: {script_path}\")\n",
                "print(f\"Source: {odoo_source}\")\n",
                "print(f\"Output: {output_file}\")\n",
                "\n",
                "# Run python script\n",
                "# We use 'llama3' as the model. Remove '--ollama-model llama3' if you want CPU-only docstring extraction.\n",
                "!python3 \"$script_path\" \"$odoo_source\" \"$output_file\" --ollama-model llama3\n",
                "\n",
                "print(\"DONE! Check the Output section of this notebook version to download your file.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}